"""
Wiki ì•± ë·° - ë©”ì¸ ê²€ìƒ‰ ë° ì •ë³´ ì•ˆë‚´
"""

from django.shortcuts import get_object_or_404
from django.db import transaction
from django.utils import timezone
from rest_framework import viewsets, status
from rest_framework.decorators import action
from rest_framework.response import Response
from drf_spectacular.utils import extend_schema, OpenApiParameter

from places.models import Place
from .models import WikiPlace, WikiSearchHistory, Review, Report
from .serializers import (
    WikiSearchQuerySerializer,
    WikiPlaceSearchResultSerializer, 
    WikiPlaceDetailSerializer,
    WikiReviewSerializer,
    WikiReviewCreateSerializer,
    WikiReportSerializer,
    WikiReportCreateSerializer,
    PopularKeywordSerializer
)
from .services import (
    search_places_by_keyword,
    parse_kakao_place_data,
    generate_ai_summary,
    # calculate_distance,
    get_popular_search_keywords
)

from .service import google

import logging

logger = logging.getLogger(__name__)


class WikiViewSet(viewsets.GenericViewSet):
    """ìœ„í‚¤ ë©”ì¸ ë·°ì…‹ - ì¥ì†Œ ê²€ìƒ‰, ìƒì„¸ ì •ë³´, ì¸ê¸° ê²€ìƒ‰ì–´"""
    queryset = WikiPlace.objects.all()

    @extend_schema(
        tags=["ğŸ”¥ìœ„í‚¤í˜ì´ì§€"],
        parameters=[WikiSearchQuerySerializer],
        responses={200: WikiPlaceSearchResultSerializer(many=True)},
        summary="3.1 ìœ„í‚¤ ê²€ìƒ‰ - ì¥ì†Œ ë° ì§€ì—­ ê²€ìƒ‰ ê°€ëŠ¥ â†’ í•«í•œ ì¥ì†Œ, ì§€ì—­ ì•ˆë‚´"
    )
    @action(detail=False, methods=["GET"])
    def search(self, request):
        """ìœ„í‚¤ ê²€ìƒ‰ ê¸°ëŠ¥ - ì¹´ì¹´ì˜¤ -> êµ¬ê¸€ API í™œìš©"""
        # ìš”ì²­ íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì‚¬
        query_serializer = WikiSearchQuerySerializer(data=request.query_params)
        query_serializer.is_valid(raise_exception=True)
        
        search_data = query_serializer.validated_data
        
        try:
            # êµ¬ê¸€ API í˜¸ì¶œ
            google_places = google.search_place(**search_data)
            
                
            #     # ê¸°ì¡´ Place ëª¨ë¸ì—ì„œ í•´ë‹¹ ì¥ì†Œ ì°¾ê¸° (ì¢Œí‘œ ê¸°ë°˜)
            #     existing_place = None
            #     try:
            #         # ì¢Œí‘œê°€ ë¹„ìŠ·í•œ ê¸°ì¡´ ì¥ì†Œ ì°¾ê¸° (ì˜¤ì°¨ í—ˆìš© ë²”ìœ„: 0.001ë„ ì•½ 100m)
            #         existing_place = Place.objects.filter(
            #             longitude__range=(place_data['longitude'] - 0.001, place_data['longitude'] + 0.001),
            #             latitude__range=(place_data['latitude'] - 0.001, place_data['latitude'] + 0.001)
            #         ).first()
            #     except Exception as e:
            #         logger.warning(f"ê¸°ì¡´ ì¥ì†Œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
                
            #     # WikiPlace ì¡°íšŒ
            #     wiki_place = None
            #     if existing_place:
            #         try:
            #             wiki_place = WikiPlace.objects.get(place=existing_place)
            #         except WikiPlace.DoesNotExist:
            #             pass
                
            #     # í‰ì  ì •ë³´ ê³„ì‚°
            #     review_score = 0.00
            #     if wiki_place:
            #         review_score = wiki_place.average_review_score
            #     elif existing_place:
            #         # ì‹¤ì‹œê°„ í‰ì  ê³„ì‚°
            #         reviews = Review.objects.filter(place=existing_place)
            #         if reviews.exists():
            #             from django.db.models import Avg
            #             avg_score = reviews.aggregate(avg=Avg('review_score'))['avg']
            #             review_score = float(avg_score) if avg_score else 0.00
                
            
            # # ê²€ìƒ‰ ê¸°ë¡ ì €ì¥ (ì„¸ì…˜ í‚¤ê°€ ìˆëŠ” ê²½ìš°)
            # if session_key:
            #     try:
            #         search_type = 'mixed'
            #         if place_name and not location_name:
            #             search_type = 'place_name'
            #         elif location_name and not place_name:
            #             search_type = 'location_name'
                    
            #         WikiSearchHistory.objects.create(
            #             search_query=search_query,
            #             search_type=search_type,
            #             result_count=len(search_results),
            #             session_key=session_key,
            #             search_longitude=user_longitude,
            #             search_latitude=user_latitude
            #         )
            #     except Exception as e:
            #         logger.warning(f"ê²€ìƒ‰ ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")
        

            
        except Exception as e:
            logger.error(f"ìœ„í‚¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return Response(
                {'detail': f'ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )
    
        return Response({"google_place" : google_places}, status=200)

    @extend_schema(
        tags=["ìœ„í‚¤ ì •ë³´ ì•ˆë‚´"],
        parameters=[
            OpenApiParameter(name="place_name", description="ì¥ì†Œëª…", required=True, type=str),
            OpenApiParameter(name="location_name", description="ì§€ì—­ëª…", required=False, type=str),
            OpenApiParameter(name="longitude", description="ê²½ë„", required=True, type=float),
            OpenApiParameter(name="latitude", description="ìœ„ë„", required=True, type=float),
        ],
        responses={200: WikiPlaceDetailSerializer},
        description="3.2.1 ê²°ê³¼ í™”ë©´ - AI ìš”ì•½ + ê¸°ë³¸ ì •ë³´ + í›„ê¸°"
    )
    @action(detail=False, methods=["GET"], url_path='detail')
    def place_detail(self, request):
        """ì¥ì†Œ ìƒì„¸ ì •ë³´ ì œê³µ - OpenAI API í™œìš© AI ìš”ì•½"""
        # ìš”ì²­ íŒŒë¼ë¯¸í„° ê²€ì¦
        place_name = request.query_params.get('place_name')
        location_name = request.query_params.get('location_name', '')
        longitude = request.query_params.get('longitude')
        latitude = request.query_params.get('latitude')
        
        if not all([place_name, longitude, latitude]):
            return Response(
                {'detail': 'place_name, longitude, latitudeëŠ” í•„ìˆ˜ íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤.'},
                status=status.HTTP_400_BAD_REQUEST
            )
        
        try:
            longitude = float(longitude)
            latitude = float(latitude)
        except ValueError:
            return Response(
                {'detail': 'ê²½ë„ì™€ ìœ„ë„ëŠ” ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.'},
                status=status.HTTP_400_BAD_REQUEST
            )
        
        try:
            # ê¸°ì¡´ Place ë˜ëŠ” WikiPlace ì°¾ê¸°
            place = None
            wiki_place = None
            
            # ì¢Œí‘œ ê¸°ë°˜ìœ¼ë¡œ ê¸°ì¡´ ì¥ì†Œ ì°¾ê¸°
            place = Place.objects.filter(
                longitude__range=(longitude - 0.001, longitude + 0.001),
                latitude__range=(latitude - 0.001, latitude + 0.001)
            ).first()
            
            # WikiPlace ì°¾ê¸° ë˜ëŠ” ìƒì„±
            if place:
                wiki_place, created = WikiPlace.objects.get_or_create(
                    place=place,
                    defaults={
                        'shop_name': place_name,
                        'kakao_place_id': '',  # ê²€ìƒ‰ì—ì„œ ì˜¨ ê²½ìš° ë³„ë„ ì—…ë°ì´íŠ¸ í•„ìš”
                    }
                )
            else:
                # ìƒˆ Place ìƒì„±
                with transaction.atomic():
                    place = Place.objects.create(
                        name=place_name,
                        address=location_name,
                        dong='',  # ë³„ë„ API í˜¸ì¶œë¡œ ì±„ìš¸ ìˆ˜ ìˆìŒ
                        longitude=longitude,
                        latitude=latitude,
                        number='',
                        running_time=''
                    )
                    
                    wiki_place = WikiPlace.objects.create(
                        place=place,
                        shop_name=place_name
                    )
            
            # ë¦¬ë·° ë°ì´í„° ìˆ˜ì§‘
            reviews = Review.objects.filter(place=place).order_by('-created_at')[:10]
            review_texts = [review.review_content for review in reviews if review.review_content]
            
            # AI ìš”ì•½ ìƒì„± (ì•„ì§ ì—†ê±°ë‚˜ ì˜¤ë˜ëœ ê²½ìš°)
            should_generate_ai_summary = (
                not wiki_place.ai_summation or
                not wiki_place.ai_summary_updated_at or
                (timezone.now() - wiki_place.ai_summary_updated_at).days > 30
            )
            
            if should_generate_ai_summary:
                try:
                    ai_summary, ai_metadata = generate_ai_summary(
                        place_name=place_name,
                        reviews=review_texts,
                        basic_info=wiki_place.basic_information
                    )
                    
                    # AI ìš”ì•½ ì •ë³´ ì—…ë°ì´íŠ¸
                    wiki_place.ai_summation = ai_summary
                    wiki_place.ai_summation_info = ai_metadata
                    wiki_place.ai_summary_updated_at = timezone.now()
                    wiki_place.save(update_fields=[
                        'ai_summation', 
                        'ai_summation_info', 
                        'ai_summary_updated_at'
                    ])
                    
                except Exception as e:
                    logger.warning(f"AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
                    # AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ ì •ë³´ëŠ” ì œê³µ
                    if not wiki_place.ai_summation:
                        wiki_place.ai_summation = f"{place_name}ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
            
            # ê¸°ë³¸ ì •ë³´ êµ¬ì„± (ì—†ëŠ” ê²½ìš°)
            if not wiki_place.basic_information:
                basic_info_parts = []
                if place.running_time:
                    basic_info_parts.append(f"ìš´ì˜ì‹œê°„: {place.running_time}")
                if place.number:
                    basic_info_parts.append(f"ì „í™”ë²ˆí˜¸: {place.number}")
                if place.address:
                    basic_info_parts.append(f"ì£¼ì†Œ: {place.address}")
                
                wiki_place.basic_information = '\n'.join(basic_info_parts) or "ê¸°ë³¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
                wiki_place.basic_information_info = {
                    'generated_at': timezone.now().isoformat(),
                    'source': 'internal_data'
                }
                wiki_place.save(update_fields=['basic_information', 'basic_information_info'])
            
            # ë¦¬ë·° í†µê³„ ì—…ë°ì´íŠ¸
            wiki_place.update_review_stats()
            
            # ë¦¬ë·° ë°ì´í„° ì§ë ¬í™”
            review_data = []
            for review in reviews:
                review_data.append({
                    'id': review.id,
                    'content': review.review_content,
                    'score': float(review.review_score),
                    'created_at': review.created_at.isoformat(),
                    'ai_review': review.ai_review,
                })
            
            # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
            response_data = {
                'place_name': place_name,
                'location_name': location_name or place.address,
                'longitude': longitude,
                'latitude': latitude,
                'shop_name': wiki_place.shop_name or place_name,
                'shop_image': wiki_place.shop_image.url if wiki_place.shop_image else None,
                'ai_summation': wiki_place.ai_summation,
                'ai_summation_info': wiki_place.ai_summation_info,
                'basic_information': wiki_place.basic_information,
                'basic_information_info': wiki_place.basic_information_info,
                'reviews': review_data,
                'average_review_score': float(wiki_place.average_review_score),
                'total_review_count': wiki_place.total_review_count,
            }
            
            serializer = WikiPlaceDetailSerializer(response_data)
            return Response(serializer.data, status=status.HTTP_200_OK)
            
        except Exception as e:
            logger.error(f"ìœ„í‚¤ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return Response(
                {'detail': f'ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @extend_schema(
        tags=["ìœ„í‚¤ ê¸°íƒ€"],
        parameters=[
            OpenApiParameter(name="limit", description="ë°˜í™˜í•  í‚¤ì›Œë“œ ê°œìˆ˜", required=False, type=int),
        ],
        responses={200: PopularKeywordSerializer(many=True)},
        description="ì¸ê¸° ê²€ìƒ‰ì–´ ëª©ë¡ ì¡°íšŒ"
    )
    @action(detail=False, methods=["GET"])
    def popular_keywords(self, request):
        """ì¸ê¸° ê²€ìƒ‰ì–´ ëª©ë¡ ë°˜í™˜"""
        limit = int(request.query_params.get('limit', 10))
        limit = min(max(limit, 1), 50)  # 1~50 ë²”ìœ„ë¡œ ì œí•œ
        
        try:
            keywords = get_popular_search_keywords(limit=limit)
            serializer = PopularKeywordSerializer(keywords, many=True)
            return Response(serializer.data, status=status.HTTP_200_OK)
        except Exception as e:
            logger.error(f"ì¸ê¸° ê²€ìƒ‰ì–´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return Response(
                {'detail': 'ì¸ê¸° ê²€ìƒ‰ì–´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )