"""
Wiki ì•± ë·° - ë©”ì¸ ê²€ìƒ‰ ë° ì •ë³´ ì•ˆë‚´
"""

from django.shortcuts import get_object_or_404
# from django.db import transaction
# from django.utils import timezone
from django.db.models import Avg

from rest_framework import viewsets, status
from rest_framework.decorators import action
from rest_framework.response import Response
from drf_spectacular.utils import extend_schema, OpenApiParameter

# from places.models import Place
from .models import WikiPlace, WikiSearchHistory, Review, Report
from .serializers import (
    WikiSearchQuerySerializer,
    WikiPlaceSearchResultSerializer, 
    WikiPlaceDetailSerializer,
    WikiReviewSerializer,
    WikiReviewCreateSerializer,
    WikiReportSerializer,
    WikiReportCreateSerializer,
    PopularKeywordSerializer
)
from .services import (
    search_places_by_keyword,
    parse_kakao_place_data,
    generate_ai_summary,
    # calculate_distance,
    get_popular_search_keywords
)

from .service import google

import logging

logger = logging.getLogger(__name__)


class WikiViewSet(viewsets.GenericViewSet):
    """ìœ„í‚¤ ë©”ì¸ ë·°ì…‹ - ì¥ì†Œ ê²€ìƒ‰, ìƒì„¸ ì •ë³´, ì¸ê¸° ê²€ìƒ‰ì–´"""
    queryset = WikiPlace.objects.all()

    @extend_schema(
        tags=["ğŸ”¥ìœ„í‚¤í˜ì´ì§€"],
        parameters=[WikiSearchQuerySerializer],
        responses={200: WikiPlaceSearchResultSerializer(many=True)},
        summary="3.1 ìœ„í‚¤ ê²€ìƒ‰ - ì¥ì†Œ ë° ì§€ì—­ ê²€ìƒ‰ ê°€ëŠ¥ â†’ í•«í•œ ì¥ì†Œ, ì§€ì—­ ì•ˆë‚´"
    )
    @action(detail=False, methods=["GET"])
    def search(self, request):
        """ìœ„í‚¤ ê²€ìƒ‰ ê¸°ëŠ¥ - ì¹´ì¹´ì˜¤ -> êµ¬ê¸€ API í™œìš©"""
        # ìš”ì²­ íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì‚¬
        query_serializer = WikiSearchQuerySerializer(data=request.query_params)
        query_serializer.is_valid(raise_exception=True)
        
        search_data = query_serializer.validated_data
        
        try:
            # êµ¬ê¸€ API í˜¸ì¶œ
            google_places = google.search_place(**search_data)
            
                
            #     # ê¸°ì¡´ Place ëª¨ë¸ì—ì„œ í•´ë‹¹ ì¥ì†Œ ì°¾ê¸° (ì¢Œí‘œ ê¸°ë°˜)
            #     existing_place = None
            #     try:
            #         # ì¢Œí‘œê°€ ë¹„ìŠ·í•œ ê¸°ì¡´ ì¥ì†Œ ì°¾ê¸° (ì˜¤ì°¨ í—ˆìš© ë²”ìœ„: 0.001ë„ ì•½ 100m)
            #         existing_place = Place.objects.filter(
            #             longitude__range=(place_data['longitude'] - 0.001, place_data['longitude'] + 0.001),
            #             latitude__range=(place_data['latitude'] - 0.001, place_data['latitude'] + 0.001)
            #         ).first()
            #     except Exception as e:
            #         logger.warning(f"ê¸°ì¡´ ì¥ì†Œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
                
            
            # # ê²€ìƒ‰ ê¸°ë¡ ì €ì¥ (ì„¸ì…˜ í‚¤ê°€ ìˆëŠ” ê²½ìš°)
            # if session_key:
            #     try:
            #         search_type = 'mixed'
            #         if place_name and not location_name:
            #             search_type = 'place_name'
            #         elif location_name and not place_name:
            #             search_type = 'location_name'
                    
            #         WikiSearchHistory.objects.create(
            #             search_query=search_query,
            #             search_type=search_type,
            #             result_count=len(search_results),
            #             session_key=session_key,
            #             search_longitude=user_longitude,
            #             search_latitude=user_latitude
            #         )
            #     except Exception as e:
            #         logger.warning(f"ê²€ìƒ‰ ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")
        

            
        except Exception as e:
            logger.error(f"ìœ„í‚¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return Response(
                {'detail': f'ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )
    
        return Response({"google_place" : google_places}, status=200)

    @extend_schema(
        tags=["ğŸ”¥ìœ„í‚¤í˜ì´ì§€"],
        parameters=[
            OpenApiParameter(name="place_id", description="ì¥ì†ŒID", required=True, type=str)
        ],
        responses={200: WikiPlaceDetailSerializer},
        summary="3.2.1 ê²°ê³¼ í™”ë©´ - AI ìš”ì•½ + ê¸°ë³¸ ì •ë³´ + í›„ê¸°"
    )
    @action(detail=False, methods=["GET"], url_path='detail')
    def place_detail(self, request):
        """ì¥ì†Œ ìƒì„¸ ì •ë³´ ì œê³µ - OpenAI API í™œìš© AI ìš”ì•½"""
        # ìš”ì²­ íŒŒë¼ë¯¸í„° ê²€ì¦
        place_id = request.query_params.get('place_id')
        
        if not place_id:
            return Response(
                {'detail': 'place_idëŠ” í•„ìˆ˜ íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤.'},
                status=status.HTTP_400_BAD_REQUEST
            )
        
        try:
            search_details = google.search_detail(place_id=place_id) 
            shop_name =search_details.get("place_name")  
        
        # IDì— í•´ë‹¹í•˜ëŠ” ìœ„í‚¤ ëª¨ë¸ì˜ ë³„ì ì— ì ‘ê·¼
            # WikiPlace ì¡°íšŒ
            wiki_place = None
            
            try:
                wiki_place, created = WikiPlace.objects.get_or_create(
                    google_place_id = place_id,
                    defaults={
                        'shop_name': shop_name
                    }
                )

                if not created: #ë“±ë¡ì€ ëëŠ”ë° ì´ë¦„ì´ ë¹„ì–´ìˆë‹¤ë©´! ë¦¬ë·° ë¨¼ì € ì“´ ê²½ìš°.. ë””ë²„ê¹…ìš©.
                    if shop_name and not (wiki_place.shop_name and wiki_place.shop_name.strip()):
                        wiki_place.shop_name = shop_name
                        wiki_place.save(update_fields=["shop_name"])

            except WikiPlace.DoesNotExist:
                # ê°ì²´ê°€ ì—†ëŠ” ê²½ìš°
                print("ì¡°íšŒëœ wikiPlace ê°ì²´ ì—†ìŒ")

            # í‰ì  ì •ë³´ ê³„ì‚°
            reviews = Review.objects.filter(wiki_place=wiki_place)
            review_score = 0.00
            if wiki_place:
                review_score = wiki_place.average_review_score
            else:
                # ì‹¤ì‹œê°„ í‰ì  ê³„ì‚°
                if reviews.exists():
                    avg_score = reviews.aggregate(avg=Avg('review_score'))['avg']
                    review_score = float(avg_score) if avg_score else 0.00
                else:
                    review_score = search_details.get("rating") #ì—†ë‹¤ë©´ êµ¬ê¸€ í‰ì 

            # ê²Œì‹œíŒ ë¦¬ë·° ì¡°íšŒ (ìµœì‹ ìˆœ/ì¶”ì²œìˆœ)
            reviews_content = wiki_place.reviews.order_by('-created_at')
            reviews_data = WikiReviewSerializer(
                reviews_content, many=True, context={'request': request}
            ).data #ì§ë ¬í™”

        except Exception as e:
            logger.error(f"ìœ„í‚¤ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return Response(
                {'detail': f'ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )
            
        
        

        # IDì— í•´ë‹¹í•˜ëŠ” ìœ„í‚¤ ëª¨ë¸ì˜ ëŒ“ê¸€ì— ì ‘ê·¼ => AI ìš”ì•½ API í˜¸ì¶œ

        return Response(
            {
                "search_detail":search_details, # êµ¬ê¸€ api ì¡°íšŒ
                "review_score":review_score, # ìœ„í‚¤ë³„ì 
                
                # AIìš”ì•½
                # ê²Œì‹œíŒ
                "reviews_content":reviews_data
            }, 
            status=200
        )
    
    


        
        
        # try:
        #     # ê¸°ì¡´ Place ë˜ëŠ” WikiPlace ì°¾ê¸°
        #     place = None
        #     wiki_place = None
            
        #     # ì¢Œí‘œ ê¸°ë°˜ìœ¼ë¡œ ê¸°ì¡´ ì¥ì†Œ ì°¾ê¸°
        #     place = Place.objects.filter(
        #         longitude__range=(longitude - 0.001, longitude + 0.001),
        #         latitude__range=(latitude - 0.001, latitude + 0.001)
        #     ).first()
            
        #     # WikiPlace ì°¾ê¸° ë˜ëŠ” ìƒì„±
        #     if place:
        #         wiki_place, created = WikiPlace.objects.get_or_create(
        #             place=place,
        #             defaults={
        #                 'shop_name': place_name,
        #                 'kakao_place_id': '',  # ê²€ìƒ‰ì—ì„œ ì˜¨ ê²½ìš° ë³„ë„ ì—…ë°ì´íŠ¸ í•„ìš”
        #             }
        #         )
        #     else:
        #         # ìƒˆ Place ìƒì„±
        #         with transaction.atomic():
        #             place = Place.objects.create(
        #                 name=place_name,
        #                 address=location_name,
        #                 dong='',  # ë³„ë„ API í˜¸ì¶œë¡œ ì±„ìš¸ ìˆ˜ ìˆìŒ
        #                 longitude=longitude,
        #                 latitude=latitude,
        #                 number='',
        #                 running_time=''
        #             )
                    
        #             wiki_place = WikiPlace.objects.create(
        #                 place=place,
        #                 shop_name=place_name
        #             )
            
        #     # ë¦¬ë·° ë°ì´í„° ìˆ˜ì§‘
        #     reviews = Review.objects.filter(place=place).order_by('-created_at')[:10]
        #     review_texts = [review.review_content for review in reviews if review.review_content]
            
        #     # AI ìš”ì•½ ìƒì„± (ì•„ì§ ì—†ê±°ë‚˜ ì˜¤ë˜ëœ ê²½ìš°)
        #     should_generate_ai_summary = (
        #         not wiki_place.ai_summation or
        #         not wiki_place.ai_summary_updated_at or
        #         (timezone.now() - wiki_place.ai_summary_updated_at).days > 30
        #     )
            
        #     if should_generate_ai_summary:
        #         try:
        #             ai_summary, ai_metadata = generate_ai_summary(
        #                 place_name=place_name,
        #                 reviews=review_texts,
        #                 basic_info=wiki_place.basic_information
        #             )
                    
        #             # AI ìš”ì•½ ì •ë³´ ì—…ë°ì´íŠ¸
        #             wiki_place.ai_summation = ai_summary
        #             wiki_place.ai_summation_info = ai_metadata
        #             wiki_place.ai_summary_updated_at = timezone.now()
        #             wiki_place.save(update_fields=[
        #                 'ai_summation', 
        #                 'ai_summation_info', 
        #                 'ai_summary_updated_at'
        #             ])
                    
        #         except Exception as e:
        #             logger.warning(f"AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        #             # AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ ì •ë³´ëŠ” ì œê³µ
        #             if not wiki_place.ai_summation:
        #                 wiki_place.ai_summation = f"{place_name}ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
            
        #     # ê¸°ë³¸ ì •ë³´ êµ¬ì„± (ì—†ëŠ” ê²½ìš°)
        #     if not wiki_place.basic_information:
        #         basic_info_parts = []
        #         if place.running_time:
        #             basic_info_parts.append(f"ìš´ì˜ì‹œê°„: {place.running_time}")
        #         if place.number:
        #             basic_info_parts.append(f"ì „í™”ë²ˆí˜¸: {place.number}")
        #         if place.address:
        #             basic_info_parts.append(f"ì£¼ì†Œ: {place.address}")
                
        #         wiki_place.basic_information = '\n'.join(basic_info_parts) or "ê¸°ë³¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        #         wiki_place.basic_information_info = {
        #             'generated_at': timezone.now().isoformat(),
        #             'source': 'internal_data'
        #         }
        #         wiki_place.save(update_fields=['basic_information', 'basic_information_info'])
            
        #     # ë¦¬ë·° í†µê³„ ì—…ë°ì´íŠ¸
        #     wiki_place.update_review_stats()
            
        #     # ë¦¬ë·° ë°ì´í„° ì§ë ¬í™”
        #     review_data = []
        #     for review in reviews:
        #         review_data.append({
        #             'id': review.id,
        #             'content': review.review_content,
        #             'score': float(review.review_score),
        #             'created_at': review.created_at.isoformat(),
        #             'ai_review': review.ai_review,
        #         })
            
        #     # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        #     response_data = {
        #         'place_name': place_name,
        #         'location_name': location_name or place.address,
        #         'longitude': longitude,
        #         'latitude': latitude,
        #         'shop_name': wiki_place.shop_name or place_name,
        #         'shop_image': wiki_place.shop_image.url if wiki_place.shop_image else None,
        #         'ai_summation': wiki_place.ai_summation,
        #         'ai_summation_info': wiki_place.ai_summation_info,
        #         'basic_information': wiki_place.basic_information,
        #         'basic_information_info': wiki_place.basic_information_info,
        #         'reviews': review_data,
        #         'average_review_score': float(wiki_place.average_review_score),
        #         'total_review_count': wiki_place.total_review_count,
        #     }
            
        #     serializer = WikiPlaceDetailSerializer(response_data)
        #     return Response(serializer.data, status=status.HTTP_200_OK)
            
        

    @extend_schema(
        tags=["ìœ„í‚¤ ê¸°íƒ€"],
        parameters=[
            OpenApiParameter(name="limit", description="ë°˜í™˜í•  í‚¤ì›Œë“œ ê°œìˆ˜", required=False, type=int),
        ],
        responses={200: PopularKeywordSerializer(many=True)},
        description="ì¸ê¸° ê²€ìƒ‰ì–´ ëª©ë¡ ì¡°íšŒ"
    )
    @action(detail=False, methods=["GET"])
    def popular_keywords(self, request):
        """ì¸ê¸° ê²€ìƒ‰ì–´ ëª©ë¡ ë°˜í™˜"""
        limit = int(request.query_params.get('limit', 10))
        limit = min(max(limit, 1), 50)  # 1~50 ë²”ìœ„ë¡œ ì œí•œ
        
        try:
            keywords = get_popular_search_keywords(limit=limit)
            serializer = PopularKeywordSerializer(keywords, many=True)
            return Response(serializer.data, status=status.HTTP_200_OK)
        except Exception as e:
            logger.error(f"ì¸ê¸° ê²€ìƒ‰ì–´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return Response(
                {'detail': 'ì¸ê¸° ê²€ìƒ‰ì–´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )